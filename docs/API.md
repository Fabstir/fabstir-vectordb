# Fabstir AI Vector Database API Documentation

**Version:** v0.1.1 (Chunked Storage Release)

## Overview

Fabstir AI Vector Database is a high-performance, decentralized vector database built on S5 storage with hybrid HNSW/IVF indexing and chunked storage for AI applications. It provides scalable vector similarity search with encryption by default, optimized for video metadata search and decentralized storage.

### Key Features

- **Chunked Storage**: Scalable partitioning with lazy loading (10K vectors/chunk default)
- **Encrypted by Default**: ChaCha20-Poly1305 encryption at rest (<5% overhead)
- **High Performance**: 58ms warm search latency, 64 MB memory for 100K vectors (Phase 6 tested)
- **Decentralized Storage**: Built on S5 network for immutable, content-addressed storage
- **Hybrid Indexing**: Combines HNSW (Hierarchical Navigable Small World) for recent data and IVF (Inverted File) for historical data
- **Multiple Interfaces**: REST API + Node.js native bindings (napi-rs) + WASM
- **Memory Efficient**: 10x memory reduction vs v0.1.0 via chunked storage with LRU cache
- **Production Ready**: Tested at scale, supports 1M+ vectors
- **Time-based Partitioning**: Automatic migration between indices based on data age
- **CBOR Serialization**: Compatible with S5 storage format

### Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Client Interfaces (v0.1.1)          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Node.js      ‚îÇ  ‚îÇ REST API     ‚îÇ  ‚îÇWASM‚îÇ ‚îÇ
‚îÇ  ‚îÇ (napi-rs)    ‚îÇ  ‚îÇ (Port 7533)  ‚îÇ  ‚îÇ    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚î¨‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ            ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ   Hybrid Index      ‚îÇ
          ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
          ‚îÇ  ‚îÇ HNSW Index  ‚îÇ    ‚îÇ
          ‚îÇ  ‚îÇ (Recent)    ‚îÇ    ‚îÇ
          ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
          ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
          ‚îÇ  ‚îÇ IVF Index   ‚îÇ    ‚îÇ
          ‚îÇ  ‚îÇ (Historical)‚îÇ    ‚îÇ
          ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ Chunked Storage     ‚îÇ
          ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
          ‚îÇ  ‚îÇ 10K/chunk   ‚îÇ    ‚îÇ
          ‚îÇ  ‚îÇ Lazy Load   ‚îÇ    ‚îÇ
          ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
          ‚îÇ         ‚îÇ           ‚îÇ
          ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
          ‚îÇ  ‚îÇ Encryption  ‚îÇ    ‚îÇ
          ‚îÇ  ‚îÇ (ChaCha20)  ‚îÇ    ‚îÇ
          ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
          ‚îÇ         ‚îÇ           ‚îÇ
          ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
          ‚îÇ  ‚îÇEnhanced S5  ‚îÇ    ‚îÇ
          ‚îÇ  ‚îÇ  (CBOR)     ‚îÇ    ‚îÇ
          ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ   S5 Network        ‚îÇ
          ‚îÇ (Decentralized)     ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**v0.1.1 Architecture Highlights**:
- **Chunked Storage**: Vectors partitioned into 10K chunks with lazy loading
- **LRU Cache**: 150 MB default cache for hot chunks
- **Encryption**: ChaCha20-Poly1305 at rest, <5% overhead
- **Multiple Clients**: Node.js native bindings (recommended), REST API, WASM

## Client Interfaces

Fabstir Vector DB provides multiple interfaces for different use cases:

### 1. Node.js Native Bindings (Recommended for SDK Integration)

**Best for:** Node.js/TypeScript applications, SDK integration, production deployments

```javascript
const { VectorDbSession } = require('@fabstir/vector-db-native');

const session = await VectorDbSession.create({
  s5Portal: 'http://localhost:5522',
  userSeedPhrase: 'your-seed-phrase',
  sessionId: 'user-123',
  encryptAtRest: true,    // Enabled by default
  chunkSize: 10000,       // 10K vectors/chunk
  cacheSizeMb: 150,       // Cache 10 chunks
});

// Add vectors with native object metadata
await session.addVectors([{
  id: 'doc1',
  vector: [...],  // 384-dim
  metadata: { text: 'Hello world', userId: 'user123' }
}]);

// Save to S5 (encrypted, chunked)
const cid = await session.saveToS5();

// Load from S5 (lazy loading)
await session.loadUserVectors(cid, { lazyLoad: true });

// Search (58ms warm cache)
const results = await session.search(queryVector, 5);
console.log(results[0].metadata.text);  // Direct property access

await session.destroy();  // CRITICAL: Clean up memory
```

**Documentation:** [Node.js Integration Guide](./sdk-reference/VECTOR_DB_INTEGRATION.md)

### 2. REST API (Language-Agnostic)

**Best for:** Microservices, language-agnostic access, HTTP-based integrations

```bash
# Production endpoint
curl -X POST http://localhost:7533/api/v1/search \
  -H "Content-Type: application/json" \
  -d '{"vector": [0.1, 0.2, ...], "k": 5}'
```

**Port:** 7533 (production), 7530-7532 (development)
**Documentation:** See [REST API Endpoints](#rest-api-endpoints) below

### 3. WASM (Browser/Portable)

**Best for:** Browser applications, portable deployments, edge computing

```javascript
import init, { VectorDB } from '@fabstir/vector-db-wasm';

await init();
const db = new VectorDB();
db.add_vector(id, vector, metadata);
const results = db.search(query_vector, k);
```

### Interface Comparison

| Feature | Node.js Native | REST API | WASM |
|---------|---------------|----------|------|
| **Performance** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Best | ‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê‚≠ê Very Good |
| **Memory Efficiency** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **S5 Persistence** | ‚úÖ Full support | ‚úÖ Full support | ‚ö†Ô∏è Limited |
| **Chunked Storage** | ‚úÖ Native | ‚úÖ Native | ‚ö†Ô∏è Limited |
| **Native Metadata** | ‚úÖ Objects | ‚ùå JSON strings | ‚ùå JSON strings |
| **Use Case** | SDK integration | Microservices | Browser apps |
| **Setup Complexity** | Low | Medium | Low |

## Installation & Setup

### Prerequisites

- **For REST API Server:**
  - Docker and Docker Compose (recommended)
  - OR: Rust 1.70+ (for native installation)
  - Enhanced S5.js running on port 5522
- **For Node.js Bindings:**
  - Node.js 18+ and npm
  - Rust toolchain (for building from source)
- **S5 Network Access:**
  - Enhanced S5.js portal (default: http://localhost:5522)
  - OR: Direct S5 network access (https://s5.vup.cx)

### Installation Steps

#### Option 1: Node.js Native Bindings (Recommended for SDK)

```bash
# Install from npm
npm install @fabstir/vector-db-native

# Or build from source
cd bindings/node
npm install
npm run build
```

**Usage:** See [Client Interfaces](#client-interfaces) section above.

#### Option 2: REST API Server with Docker

```bash
# Clone the repository
git clone https://github.com/fabstir/fabstir-ai-vector-db.git
cd fabstir-ai-vector-db

# Start production container
docker-compose -f docker-compose.dev.yml up -d vector-db-prod

# REST API will be available at:
# http://localhost:7533/api/v1
```

#### Option 3: Build REST API from Source

```bash
# Clone the repository
git clone https://github.com/fabstir/fabstir-ai-vector-db.git
cd fabstir-ai-vector-db

# Build the Rust backend
cargo build --release --bin server

# Run the server
VECTOR_DB_PORT=7533 cargo run --release --bin server
```

**Note:** For production deployment, you must have Enhanced S5.js running on port 5522. See [Enhanced S5.js setup](../partners/S5/GitHub/s5.js/).

### Configuration Options

#### REST API Server Configuration

Environment variables can be set in `.env` file or passed directly:

```bash
# S5 Storage Configuration
S5_MODE=real                              # Storage mode: "real" or "mock" (default: real)
S5_PORTAL_URL=http://localhost:5522       # Enhanced S5.js URL (required)
S5_SEED_PHRASE=your-seed-phrase-here      # S5 seed phrase (12 or 24 words)
S5_SEED_PHRASE_FILE=/path/to/seed.txt     # Optional: Path to seed phrase file
S5_API_KEY=your-api-key                   # Optional: S5 API key
S5_CONNECTION_TIMEOUT=30000               # Connection timeout in ms (default: 30000)
S5_RETRY_ATTEMPTS=3                       # Number of retry attempts (default: 3)

# Vector Database Configuration
VECTOR_DIMENSION=384                      # Vector dimensions (default: 384 for all-MiniLM-L6-v2)
MAX_VECTORS_PER_INDEX=1000000             # Maximum vectors per index

# Chunked Storage Configuration (v0.1.1)
CHUNK_SIZE=10000                          # Vectors per chunk (default: 10000)
CACHE_SIZE_MB=150                         # Chunk cache size in MB (default: 150)
LAZY_LOAD=true                            # Enable lazy loading (default: true)
ENCRYPT_AT_REST=true                      # Enable encryption (default: true)

# Index Configuration
HNSW_M=16                                 # HNSW connectivity parameter
HNSW_EF_CONSTRUCTION=200                  # HNSW construction quality
IVF_N_CLUSTERS=256                        # IVF number of clusters
IVF_N_PROBE=16                            # IVF clusters to search

# Server Configuration
VECTOR_DB_HOST=0.0.0.0                    # Server host (default: 0.0.0.0)
VECTOR_DB_PORT=7533                       # REST API port (production: 7533, dev: 7530-7532)
VECTOR_DB_MAX_REQUEST_SIZE=10485760       # Max request size (10MB)
VECTOR_DB_TIMEOUT_SECS=30                 # Request timeout
VECTOR_DB_CORS_ORIGINS=http://localhost:3000  # CORS origins
```

#### Node.js Bindings Configuration (v0.1.1)

For Node.js native bindings, configuration is passed programmatically:

```javascript
const config = {
  s5Portal: 'http://localhost:5522',      // Enhanced S5.js endpoint
  userSeedPhrase: 'your-seed-phrase',     // 12 or 24 words
  sessionId: 'session-123',               // Unique session ID

  // Optional: Chunked storage tuning
  chunkSize: 10000,                       // 10K vectors/chunk (default)
  cacheSizeMb: 150,                       // 150 MB cache (default)
  encryptAtRest: true,                    // ChaCha20-Poly1305 (default)

  // Optional: Advanced settings
  memoryBudgetMb: 512,                    // Memory limit (default: 512)
  debug: false,                           // Debug logging (default: false)
};

const session = await VectorDbSession.create(config);
```

**Tuning Guidelines:**
- **Memory-constrained:** `chunkSize: 5000`, `cacheSizeMb: 75`
- **Performance-focused:** `chunkSize: 20000`, `cacheSizeMb: 300`
- **Large datasets (1M+):** `chunkSize: 20000`, `cacheSizeMb: 300`

See [Performance Tuning Guide](./PERFORMANCE_TUNING.md) for detailed optimization strategies.

### Docker Setup

The project includes Docker configuration for production and development:

```yaml
# docker-compose.dev.yml (excerpt)
version: "3.8"

services:
  vector-db-prod:
    build:
      context: .
      dockerfile: Dockerfile.production
    ports:
      - "7533:7533"  # Production REST API
    environment:
      - S5_PORTAL_URL=http://host.docker.internal:5522
      - VECTOR_DIMENSION=${VECTOR_DIMENSION:-384}
      - CHUNK_SIZE=${CHUNK_SIZE:-10000}
      - CACHE_SIZE_MB=${CACHE_SIZE_MB:-150}
      - ENCRYPT_AT_REST=${ENCRYPT_AT_REST:-true}
    extra_hosts:
      - "host.docker.internal:host-gateway"
```

**Important:** Use `host.docker.internal:5522` for S5 portal URL when running in Docker to access Enhanced S5.js on the host.

## Core API Reference

### REST API Endpoints

**Base URL (Production):** `http://localhost:7533/api/v1`
**Development Ports:** 7530-7532

#### Health Check

```http
GET /health
```

Response:
```json
{
  "status": "healthy",
  "version": "0.1.0",
  "storage": {
    "mode": "mock",
    "connected": true,
    "base_url": "http://localhost:5524"
  },
  "indices": {
    "hnsw": {
      "healthy": true,
      "vector_count": 1234
    },
    "ivf": {
      "healthy": true,
      "vector_count": 5678
    }
  }
}
```

The `storage` object provides information about the S5 storage backend:
- `mode`: Either "mock" or "real" depending on configuration
- `connected`: Whether the storage backend is accessible
- `base_url`: Present for mock mode, shows the mock server URL
- `portal_url`: Present for real mode, shows the S5 portal URL

#### Vector Operations

##### Insert Vector

```http
POST /vectors
Content-Type: application/json

{
  "id": "vec_12345",
  "vector": [0.1, 0.2, 0.3, ...],
  "metadata": {
    "video_id": "video_abc",
    "title": "Example Video",
    "tags": ["ai", "tutorial"]
  }
}
```

Response:
```json
{
  "id": "vec_12345",
  "index": "recent",
  "timestamp": "2025-01-15T10:30:00Z"
}
```

##### Batch Insert

```http
POST /vectors/batch
Content-Type: application/json

{
  "vectors": [
    {
      "id": "vec_001",
      "vector": [0.1, 0.2, ...],
      "metadata": {...}
    },
    {
      "id": "vec_002",
      "vector": [0.3, 0.4, ...],
      "metadata": {...}
    }
  ]
}
```

Response:
```json
{
  "successful": 2,
  "failed": 0,
  "errors": []
}
```

##### Get Vector

```http
GET /vectors/{id}
```

Response:
```json
{
  "id": "vec_12345",
  "vector": [0.1, 0.2, 0.3, ...],
  "metadata": {
    "video_id": "video_abc",
    "title": "Example Video"
  },
  "index": "recent",
  "timestamp": "2025-01-15T10:30:00Z"
}
```

##### Delete Vector

```http
DELETE /vectors/{id}
```

Response: `204 No Content`

#### Search Operations

##### Vector Search

```http
POST /search
Content-Type: application/json

{
  "vector": [0.1, 0.2, 0.3, ...],
  "k": 10,
  "filter": {
    "tags": ["ai", "tutorial"]
  },
  "options": {
    "search_recent": true,
    "search_historical": true,
    "hnsw_ef": 50,
    "ivf_n_probe": 16,
    "timeout_ms": 5000,
    "include_metadata": true,
    "score_threshold": 0.8
  }
}
```

Response:
```json
{
  "results": [
    {
      "id": "vec_12345",
      "distance": 0.15,
      "score": 0.92,
      "metadata": {
        "video_id": "video_abc",
        "title": "Example Video"
      }
    }
  ],
  "search_time_ms": 23.5,
  "indices_searched": 2,
  "partial_results": false
}
```

#### Admin Operations

##### Get Statistics

```http
GET /admin/statistics
```

Response:
```json
{
  "total_vectors": 10000,
  "recent_vectors": 2000,
  "historical_vectors": 8000,
  "memory_usage": {
    "total_bytes": 104857600,
    "hnsw_bytes": 41943040,
    "ivf_bytes": 62914560
  }
}
```

##### Trigger Migration

```http
POST /admin/migrate
```

Response:
```json
{
  "vectors_migrated": 500,
  "duration_ms": 1234.5
}
```

##### Rebalance Clusters

```http
POST /admin/rebalance
```

Response:
```json
{
  "clusters_modified": 32,
  "vectors_moved": 1500
}
```

##### Create Backup

```http
POST /admin/backup
Content-Type: application/json

{
  "backup_path": "/backups/vector-db-backup.tar.gz",
  "compress": true
}
```

Response:
```json
{
  "backup_size": 52428800,
  "vectors_backed_up": 10000,
  "compression_ratio": 0.65
}
```

#### Streaming Operations

##### Server-Sent Events (SSE)

```http
GET /stream/updates
```

Event stream format:
```
event: vector_added
data: {"id": "vec_12345", "index": "recent"}

event: migration_started
data: {"vectors_to_migrate": 500}

event: migration_completed
data: {"vectors_migrated": 500, "duration_ms": 1234}
```

##### WebSocket Connection

```http
GET /ws
Upgrade: websocket
```

## Future Features (Planned)

The following features are planned for future releases:

### MCP Server Integration (Planned)

**Status:** üöß Not yet implemented

The MCP (Model Context Protocol) server will enable direct integration with LLMs like Claude. This feature is planned for a future release and will provide:

- Direct vector search tool for LLMs
- Vector insertion/management via MCP
- Seamless integration with Claude Desktop and other MCP clients
- Real-time context retrieval for AI applications

**Tracking:** See GitHub issues for progress updates.

## Data Models

### Vector Format

```typescript
interface Vector {
  id: string;           // Unique identifier (e.g., "vec_12345")
  vector: number[];     // Float32 array of embeddings
  metadata?: object;    // Optional metadata
}
```

### VectorId

Vectors are identified using a 32-byte BLAKE3 hash:

```rust
pub struct VectorId([u8; 32]);

impl VectorId {
    pub fn new() -> Self;                    // Generate random ID
    pub fn from_string(s: &str) -> Self;     // Hash from string
    pub fn hash_hex(&self) -> String;        // Hex representation
    pub fn to_string(&self) -> String;       // Human-readable format
}
```

### Embedding

```rust
pub struct Embedding {
    data: Vec<f32>,
}

impl Embedding {
    pub fn dimension(&self) -> usize;
    pub fn magnitude(&self) -> f32;
    pub fn normalize(&self) -> Self;
    pub fn cosine_similarity(&self, other: &Self) -> f32;
    pub fn euclidean_distance(&self, other: &Self) -> f32;
}
```

### Video Metadata

```typescript
interface VideoMetadata {
  video_id: string;
  title: string;
  description?: string;
  tags: string[];
  duration_seconds: number;
  upload_timestamp: string;  // ISO 8601
  model_name: string;        // Embedding model used
  extra: Record<string, any>;
}
```

### Search Result

```typescript
interface SearchResult {
  id: string;
  distance: number;    // Euclidean distance
  score: number;       // Normalized similarity score (0-1)
  metadata?: object;
}
```

### Index Configuration

#### HNSW Configuration

```rust
pub struct HNSWConfig {
    pub max_connections: usize,          // M parameter (default: 16)
    pub max_connections_layer_0: usize,  // M*2 for layer 0 (default: 32)
    pub ef_construction: usize,          // Construction quality (default: 200)
    pub seed: Option<u64>,              // Random seed
}
```

#### IVF Configuration

```rust
pub struct IVFConfig {
    pub n_clusters: usize,      // Number of clusters (default: 256)
    pub n_probe: usize,         // Clusters to search (default: 16)
    pub train_size: usize,      // Training set size (default: 10000)
    pub max_iterations: usize,  // K-means iterations (default: 25)
    pub seed: Option<u64>,      // Random seed
}
```

#### Hybrid Configuration

```rust
pub struct HybridConfig {
    pub recent_threshold: Duration,      // Age threshold (default: 7 days)
    pub hnsw_config: HNSWConfig,
    pub ivf_config: IVFConfig,
    pub migration_batch_size: usize,     // Batch size for migration (default: 100)
    pub auto_migrate: bool,              // Auto-migrate old vectors (default: true)
}
```

## S5 Storage Integration

### How Vectors are Stored in S5

The database uses S5's decentralized storage with the following structure:

1. **Content Addressing**: Each vector is stored with a CID (Content Identifier)
2. **CBOR Serialization**: All data is serialized using CBOR format for S5 compatibility
3. **Compression**: Optional zstd compression for large vectors
4. **Immutability**: Once stored, vectors cannot be modified (only new versions can be added)

### Storage Layout

```
/vectors/
  ‚îú‚îÄ‚îÄ recent/           # HNSW index data
  ‚îÇ   ‚îú‚îÄ‚îÄ nodes/        # Vector nodes
  ‚îÇ   ‚îî‚îÄ‚îÄ graph/        # HNSW graph connections
  ‚îú‚îÄ‚îÄ historical/       # IVF index data
  ‚îÇ   ‚îú‚îÄ‚îÄ centroids/    # Cluster centroids
  ‚îÇ   ‚îî‚îÄ‚îÄ inverted/     # Inverted lists
  ‚îî‚îÄ‚îÄ metadata/         # Vector metadata
```

### S5 Client Configuration

```rust
pub struct S5Config {
    pub node_url: String,           // S5 portal URL
    pub api_key: Option<String>,    // Optional API key
    pub enable_compression: bool,   // Enable compression
    pub cache_size: usize,         // Local cache size
}
```

### Seed Phrase Management

The S5 seed phrase can be:
1. Set via `S5_SEED_PHRASE` environment variable
2. Loaded from a file via `S5_SEED_PHRASE_FILE` environment variable
3. Generated automatically and stored securely
4. Retrieved via admin API (with proper authentication)

#### Using Environment Variable
```bash
# Set custom seed phrase (must be 12 or 24 words)
export S5_SEED_PHRASE="your twelve word mnemonic seed phrase here for s5 storage access"
```

#### Using Seed Phrase File (Recommended)
```bash
# Create seed phrase file with proper permissions
echo "your twelve word seed phrase goes here like this example phrase" > ~/.s5-seed
chmod 600 ~/.s5-seed  # Restrict access to owner only

# Use file for configuration
export S5_SEED_PHRASE_FILE=~/.s5-seed
```

**Security Notes**:
- Seed phrases must contain exactly 12 or 24 words
- On Unix systems, seed phrase files with world-readable permissions will trigger a warning
- The file method takes precedence over the environment variable if both are set
- Seed phrases are never logged or exposed in API responses

### Portal Configuration

```bash
# Use default S5 portal
export S5_PORTAL_URL=https://s5.vup.cx

# Or use custom portal
export S5_PORTAL_URL=http://localhost:5524
```

## HAMT Sharding

### Automatic Activation

HAMT (Hash Array Mapped Trie) sharding automatically activates when:
- Vector count exceeds `HAMT_ACTIVATION_THRESHOLD` (default: 1000)
- Provides O(log n) lookup performance
- Maintains compatibility with S5's HAMT implementation

### Performance Characteristics

| Vector Count | Without HAMT | With HAMT   |
|-------------|--------------|-------------|
| < 1,000     | O(1)         | O(1)        |
| 10,000      | O(n)         | O(log n)    |
| 100,000     | O(n)         | O(log n)    |
| 1,000,000   | O(n)         | O(log n)    |

### Configuration Options

```bash
# Activation threshold
HAMT_ACTIVATION_THRESHOLD=1000

# Branching factor (affects tree depth)
HAMT_BRANCHING_FACTOR=32

# Maximum depth
HAMT_MAX_DEPTH=10
```

### HAMT Structure

```
Root Node
‚îú‚îÄ Branch[0-31]
‚îÇ  ‚îú‚îÄ Branch[0-31]
‚îÇ  ‚îÇ  ‚îî‚îÄ Leaf ‚Üí Vector Data
‚îÇ  ‚îî‚îÄ Leaf ‚Üí Vector Data
‚îî‚îÄ Branch[32-63]
   ‚îî‚îÄ Leaf ‚Üí Vector Data
```

## Examples

### Basic Usage Examples

#### 1. Initialize Client (TypeScript)

```typescript
import { VectorDBClient } from 'fabstir-ai-vector-db';

const client = new VectorDBClient({
  apiUrl: 'http://localhost:7530',
  apiKey: process.env.VECTOR_DB_API_KEY
});

// Check health
const health = await client.health();
console.log('Database status:', health.status);
```

#### 2. Insert Vectors

```typescript
// Single vector insertion
const vector = await generateEmbedding("AI tutorial video");
const result = await client.insertVector({
  id: 'vec_001',
  vector: vector,
  metadata: {
    video_id: 'video_123',
    title: 'Introduction to AI',
    tags: ['ai', 'tutorial', 'beginner']
  }
});

// Batch insertion
const vectors = await Promise.all([
  generateEmbedding("Machine learning basics"),
  generateEmbedding("Deep learning fundamentals"),
  generateEmbedding("Neural networks explained")
]);

const batchResult = await client.batchInsert({
  vectors: vectors.map((vec, i) => ({
    id: `vec_${i + 100}`,
    vector: vec,
    metadata: {
      video_id: `video_${i + 100}`,
      title: `Lesson ${i + 1}`
    }
  }))
});
```

#### 3. Search Vectors

```typescript
// Basic search
const queryVector = await generateEmbedding("How do neural networks work?");
const results = await client.search({
  vector: queryVector,
  k: 5
});

// Advanced search with options
const advancedResults = await client.search({
  vector: queryVector,
  k: 10,
  filter: {
    tags: ['neural-networks', 'deep-learning']
  },
  options: {
    search_recent: true,
    search_historical: true,
    hnsw_ef: 100,        // Higher = better quality, slower
    ivf_n_probe: 32,     // More clusters = better quality, slower
    timeout_ms: 5000,
    include_metadata: true,
    score_threshold: 0.75
  }
});
```

### Advanced Queries

#### 1. Time-based Search

```typescript
// Search only recent vectors (last 24 hours)
const recentResults = await client.search({
  vector: queryVector,
  k: 10,
  options: {
    search_recent: true,
    search_historical: false,
    recent_threshold_override: 24 * 60 * 60 * 1000  // 24 hours in ms
  }
});
```

#### 2. Filtered Search

```typescript
// Complex metadata filtering
const filteredResults = await client.search({
  vector: queryVector,
  k: 20,
  filter: {
    $and: [
      { tags: { $in: ['ai', 'ml', 'deep-learning'] } },
      { duration_seconds: { $gte: 300, $lte: 1800 } },
      { model_name: 'text-embedding-ada-002' }
    ]
  }
});
```

#### 3. Streaming Updates

```typescript
// Subscribe to real-time updates
const eventSource = new EventSource('http://localhost:7530/stream/updates');

eventSource.addEventListener('vector_added', (event) => {
  const data = JSON.parse(event.data);
  console.log('New vector added:', data.id);
});

eventSource.addEventListener('migration_completed', (event) => {
  const data = JSON.parse(event.data);
  console.log(`Migration completed: ${data.vectors_migrated} vectors`);
});
```

### Integration with AI Applications

#### 1. OpenAI Integration

```typescript
import OpenAI from 'openai';
import { VectorDBClient } from 'fabstir-ai-vector-db';

const openai = new OpenAI();
const vectorDB = new VectorDBClient();

async function indexVideo(videoTranscript: string, metadata: any) {
  // Generate embedding
  const response = await openai.embeddings.create({
    model: "text-embedding-ada-002",
    input: videoTranscript
  });
  
  const embedding = response.data[0].embedding;
  
  // Store in vector database
  await vectorDB.insertVector({
    id: `vec_${metadata.video_id}`,
    vector: embedding,
    metadata: {
      ...metadata,
      model_name: 'text-embedding-ada-002',
      indexed_at: new Date().toISOString()
    }
  });
}

async function semanticSearch(query: string) {
  // Generate query embedding
  const response = await openai.embeddings.create({
    model: "text-embedding-ada-002",
    input: query
  });
  
  const queryEmbedding = response.data[0].embedding;
  
  // Search similar videos
  return await vectorDB.search({
    vector: queryEmbedding,
    k: 10,
    options: {
      include_metadata: true,
      score_threshold: 0.8
    }
  });
}
```

#### 2. LangChain Integration

```typescript
import { VectorDBStore } from 'fabstir-ai-vector-db/langchain';
import { OpenAIEmbeddings } from 'langchain/embeddings/openai';

// Create vector store
const vectorStore = new VectorDBStore({
  embeddings: new OpenAIEmbeddings(),
  apiUrl: 'http://localhost:7530'
});

// Add documents
await vectorStore.addDocuments([
  { pageContent: "AI fundamentals", metadata: { topic: "ai" } },
  { pageContent: "Machine learning basics", metadata: { topic: "ml" } }
]);

// Similarity search
const results = await vectorStore.similaritySearch("What is AI?", 5);
```

### Using with Different Embedding Models

#### 1. Cohere Embeddings

```typescript
import cohere from 'cohere-ai';

cohere.init(process.env.COHERE_API_KEY);

async function generateCohereEmbedding(text: string) {
  const response = await cohere.embed({
    texts: [text],
    model: 'embed-english-v3.0'
  });
  
  return response.body.embeddings[0];
}
```

#### 2. Sentence Transformers (Python)

```python
from sentence_transformers import SentenceTransformer
import requests

model = SentenceTransformer('all-MiniLM-L6-v2')

def index_video(video_text, metadata):
    # Generate embedding
    embedding = model.encode(video_text).tolist()
    
    # Store in vector database
    response = requests.post(
        'http://localhost:7530/vectors',
        json={
            'id': f"vec_{metadata['video_id']}",
            'vector': embedding,
            'metadata': metadata
        }
    )
    return response.json()
```

#### 3. Custom Embeddings

```typescript
// Using your own embedding model
async function customEmbedding(text: string): Promise<number[]> {
  // Your custom embedding logic
  const response = await fetch('http://your-model-api/embed', {
    method: 'POST',
    body: JSON.stringify({ text }),
    headers: { 'Content-Type': 'application/json' }
  });
  
  const data = await response.json();
  return data.embedding;
}

// Use with vector database
const embedding = await customEmbedding("Video content");
await vectorDB.insertVector({
  id: 'custom_vec_001',
  vector: embedding,
  metadata: {
    model_name: 'custom-model-v1',
    dimension: embedding.length
  }
});
```

## Performance & Scalability

### v0.1.1 Benchmarks (Phase 6 - Actual Results)

**Test Environment:** Node.js native bindings, all-MiniLM-L6-v2 embeddings (384-dim)

#### 100K Vectors - Production Ready ‚úÖ

| Metric | v0.1.0 | v0.1.1 | Improvement |
|--------|--------|--------|-------------|
| **Load Time** | ~4000ms | **685ms** | **6x faster** |
| **Memory Usage** | ~640 MB | **64 MB** | **10x reduction** |
| **Search (warm)** | ~60ms | **58ms** | Similar |
| **Search (cold)** | ~1200ms | **~1000ms** | ~17% faster |
| **Encryption Overhead** | N/A | **<5%** | ChaCha20-Poly1305 |

#### Key Improvements (v0.1.1)

- ‚úÖ **Chunked Storage**: 10K vectors/chunk with lazy loading
- ‚úÖ **LRU Cache**: 150 MB default, configurable
- ‚úÖ **Encryption**: Enabled by default, minimal overhead
- ‚úÖ **Memory Efficiency**: 10x reduction via lazy loading
- ‚úÖ **Scalability**: Tested to 1M+ vectors

### Scaling Considerations

#### 1. Memory Usage (v0.1.1 Chunked Storage)

**With Lazy Loading (Default):**
- **100K vectors**: ~64 MB (10 chunks √ó 6.4 MB/chunk cached)
- **500K vectors**: ~128 MB (cache limited to ~10 chunks)
- **1M+ vectors**: ~150-200 MB (LRU cache maintains constant memory)

**Formula:**
```
Memory ‚âà cacheSizeMb + (active_chunks √ó ~6-15 MB)
```

**Tuning:**
- Memory-constrained: `cacheSizeMb: 75` ‚Üí ~100 MB total
- Performance-focused: `cacheSizeMb: 300` ‚Üí ~350 MB total

#### 2. Storage Requirements (384-dim vectors)

**v0.1.1 with Chunked Storage + Encryption:**
- **Raw**: 384 √ó 4 bytes = 1.5 KB per vector
- **Chunked + Encrypted**: ~1.6 KB per vector (<5% overhead)
- **Indexes (HNSW)**: Additional ~500 bytes per vector

**Examples:**
- 100K vectors: ~200 MB (storage)
- 1M vectors: ~2 GB (storage)
- 10M vectors: ~20 GB (storage)

#### 3. Query Performance Optimization

```typescript
// Optimize for speed (lower quality)
const fastSearch = {
  hnsw_ef: 50,      // Lower ef = faster
  ivf_n_probe: 8,   // Fewer probes = faster
  timeout_ms: 1000
};

// Optimize for quality (slower)
const qualitySearch = {
  hnsw_ef: 200,     // Higher ef = better quality
  ivf_n_probe: 32,  // More probes = better quality
  timeout_ms: 5000
};

// Balanced approach
const balancedSearch = {
  hnsw_ef: 100,
  ivf_n_probe: 16,
  timeout_ms: 3000
};
```

### Best Practices

#### 1. Batch Operations

```typescript
// Good: Batch insert
await client.batchInsert({
  vectors: largeArrayOfVectors  // Insert 1000 at once
});

// Bad: Individual inserts
for (const vector of largeArrayOfVectors) {
  await client.insertVector(vector);  // Slow!
}
```

#### 2. Connection Pooling

```typescript
// Reuse client instances
const client = new VectorDBClient({
  apiUrl: 'http://localhost:7530',
  maxConnections: 10,
  keepAlive: true
});

// Use the same client instance across your application
export default client;
```

#### 3. Index Tuning

```bash
# For write-heavy workloads
HNSW_EF_CONSTRUCTION=100  # Lower for faster inserts
IVF_N_CLUSTERS=128        # Fewer clusters

# For read-heavy workloads
HNSW_EF_CONSTRUCTION=400  # Higher for better search quality
IVF_N_CLUSTERS=512        # More clusters for better distribution
```

#### 4. Migration Strategy

```typescript
// Configure automatic migration
const config = {
  recent_threshold: 7 * 24 * 60 * 60 * 1000,  // 7 days
  migration_batch_size: 1000,
  auto_migrate: true
};

// Or manually trigger migration during off-peak
await client.admin.migrate();
```

## Error Handling

### Common Errors and Solutions

#### 1. Configuration Errors

```typescript
// Error: S5_PORTAL_URL required for real mode
// Solution: Set the portal URL when using real mode
export S5_MODE=real
export S5_PORTAL_URL=https://s5.vup.cx

// Error: Invalid URL format for S5_PORTAL_URL: must start with http:// or https://
// Solution: Ensure URLs have proper protocol
export S5_PORTAL_URL=https://s5.vup.cx  // ‚úì Correct
export S5_PORTAL_URL=s5.vup.cx          // ‚úó Wrong

// Error: Invalid seed phrase: expected 12 or 24 words, got 10
// Solution: Use a valid BIP39 seed phrase with correct word count
export S5_SEED_PHRASE="twelve words go here for proper seed phrase format example test"
```

#### 2. Dimension Mismatch

```typescript
// Error: DimensionMismatch: expected 1536, got 384
// Solution: Ensure all vectors have the same dimension
const EXPECTED_DIMENSION = 1536;

function validateVector(vector: number[]): void {
  if (vector.length !== EXPECTED_DIMENSION) {
    throw new Error(`Vector must have ${EXPECTED_DIMENSION} dimensions`);
  }
}
```

#### 3. Duplicate Vector ID

```typescript
// Error: DuplicateVector: Vector with ID vec_123 already exists
// Solution: Use unique IDs or check existence first
try {
  await client.insertVector({ id, vector, metadata });
} catch (error) {
  if (error.code === 'DUPLICATE_VECTOR') {
    // Update existing vector instead
    await client.updateVector({ id, vector, metadata });
  }
}
```

#### 4. Index Not Initialized

```typescript
// Error: NotInitialized: Index not trained
// Solution: Initialize the index with training data
const trainingVectors = await loadTrainingData();
await client.admin.initializeIndex(trainingVectors);
```

#### 5. S5 Connection Issues

```typescript
// Error: NetworkError: Failed to connect to S5 portal
// Solution: Implement retry logic
async function retryOperation<T>(
  operation: () => Promise<T>,
  maxRetries = 3
): Promise<T> {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await operation();
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, 1000 * Math.pow(2, i)));
    }
  }
  throw new Error('Max retries exceeded');
}
```

### Debugging Tips

#### 1. Enable Debug Logging

```bash
# Set environment variable
export RUST_LOG=vector_db=debug,tower_http=debug

# Or in .env file
RUST_LOG=vector_db=debug,tower_http=debug
```

#### 2. Monitor Performance

```typescript
// Use the statistics endpoint
const stats = await client.admin.getStatistics();
console.log('Vector distribution:', {
  recent: stats.recent_vectors,
  historical: stats.historical_vectors,
  memoryUsage: stats.memory_usage
});
```

#### 3. Health Checks

```typescript
// Regular health monitoring
setInterval(async () => {
  try {
    const health = await client.health();
    if (health.status !== 'healthy') {
      console.error('Database unhealthy:', health);
      // Trigger alerts
    }
  } catch (error) {
    console.error('Health check failed:', error);
  }
}, 30000);  // Every 30 seconds
```

#### 4. Trace Requests

```typescript
// Add request ID for tracing
const requestId = generateRequestId();
const result = await client.search({
  vector: queryVector,
  k: 10,
  headers: {
    'X-Request-ID': requestId
  }
});

// Check server logs for this request ID
```

## API Rate Limits and Quotas

### Default Limits

- **Request Rate**: 1000 requests/minute per IP
- **Batch Size**: Maximum 1000 vectors per batch
- **Request Size**: 10MB per request
- **Query Timeout**: 30 seconds
- **Connection Limit**: 100 concurrent connections

## Implementation Status

### Fully Implemented Endpoints
- ‚úÖ `GET /health` - Health check
- ‚úÖ `POST /vectors` - Insert single vector
- ‚úÖ `POST /vectors/batch` - Batch insert vectors
- ‚úÖ `GET /vectors/{id}` - Get vector by ID
- ‚úÖ `DELETE /vectors/{id}` - Delete vector
- ‚úÖ `POST /search` - Vector similarity search

### Partially Implemented Endpoints
These endpoints have placeholder implementations that return default/empty responses:
- ‚ö†Ô∏è `GET /admin/statistics` - Returns zeros (TODO: implement actual statistics)
- ‚ö†Ô∏è `POST /admin/migrate` - Returns zeros (TODO: implement migration logic)
- ‚ö†Ô∏è `POST /admin/rebalance` - Returns zeros (TODO: implement rebalancing)
- ‚ö†Ô∏è `POST /admin/backup` - Returns zeros (TODO: implement backup functionality)
- ‚ö†Ô∏è `GET /stream/updates` - Returns empty stream (TODO: implement SSE events)
- ‚ö†Ô∏è `GET /ws` - Returns status code only (TODO: implement WebSocket handler)

### Configuring Limits

```bash
# Environment variables
RATE_LIMIT_PER_MINUTE=1000
MAX_BATCH_SIZE=1000
MAX_REQUEST_SIZE=10485760
QUERY_TIMEOUT_MS=30000
MAX_CONNECTIONS=100
```

### Handling Rate Limits

```typescript
// Implement exponential backoff
async function handleRateLimit<T>(
  operation: () => Promise<T>
): Promise<T> {
  const maxRetries = 5;
  let delay = 1000; // Start with 1 second
  
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await operation();
    } catch (error) {
      if (error.status === 429) { // Rate limited
        await new Promise(resolve => setTimeout(resolve, delay));
        delay *= 2; // Exponential backoff
        continue;
      }
      throw error;
    }
  }
  throw new Error('Rate limit exceeded after retries');
}
```

## Security Considerations

### Authentication

```typescript
// API Key authentication
const client = new VectorDBClient({
  apiUrl: 'http://localhost:7530',
  apiKey: process.env.VECTOR_DB_API_KEY
});

// Bearer token in headers
const response = await fetch('http://localhost:7530/vectors', {
  headers: {
    'Authorization': `Bearer ${apiKey}`,
    'Content-Type': 'application/json'
  }
});
```

### Encryption

- **Transport**: Use HTTPS in production
- **Storage**: Vectors are encrypted at rest in S5
- **Keys**: Store API keys and seed phrases securely

### Access Control

```typescript
// Example middleware for role-based access
app.use('/admin/*', requireRole('admin'));
app.use('/vectors/delete', requireRole('editor'));
app.use('/search', requireRole('reader'));
```

## Troubleshooting Guide

### Common Issues

1. **Slow Search Performance**
   - Check index statistics
   - Increase `hnsw_ef` for recent index
   - Increase `ivf_n_probe` for historical index
   - Consider adding more RAM

2. **High Memory Usage**
   - Enable compression
   - Reduce `HNSW_M` parameter
   - Implement pagination for large results
   - Monitor with `admin/statistics`

3. **Failed Migrations**
   - Check disk space
   - Verify S5 connectivity
   - Review migration logs
   - Manually trigger with smaller batches

4. **Connection Timeouts**
   - Increase timeout values
   - Check network connectivity
   - Verify S5 portal status
   - Implement retry logic

### Support Resources

- GitHub Issues: https://github.com/fabstir/fabstir-ai-vector-db/issues
- Documentation: https://docs.fabstir.ai/vector-db
- Community Discord: https://discord.gg/fabstir
- Email Support: support@fabstir.ai

---

## Version History

### v0.1.1 - Chunked Storage Release (2025-01-28)

**Major Features:**
- ‚úÖ **Chunked Storage**: Scalable partitioning with 10K vectors/chunk default
- ‚úÖ **Lazy Loading**: On-demand chunk loading with LRU cache (150 MB default)
- ‚úÖ **Encryption by Default**: ChaCha20-Poly1305 at rest (<5% overhead)
- ‚úÖ **Node.js Native Bindings**: Production-ready napi-rs bindings (v0.1.0)
- ‚úÖ **Memory Optimization**: 10x reduction (64 MB for 100K vectors vs 640 MB in v0.1.0)
- ‚úÖ **Performance**: 6x faster load times (685ms vs ~4000ms)

**API Changes:**
- Added `chunkSize`, `cacheSizeMb`, `encryptAtRest` to `VectorDbConfig`
- Added `lazyLoad` option to `loadUserVectors()`
- Updated default S5 timeout to 30 seconds for real S5 operations
- Changed production port from 7530 to 7533

**Performance (Phase 6 Tested - 100K vectors):**
- Load: 685ms
- Memory: 64 MB
- Search (warm): 58ms
- Search (cold): ~1000ms
- Encryption overhead: <5%

**Documentation:**
- Added [Performance Tuning Guide](./PERFORMANCE_TUNING.md)
- Updated [Vector DB Integration Guide](./sdk-reference/VECTOR_DB_INTEGRATION.md)
- Refreshed README with v0.1.1 features

### v0.1.0 - Initial Production Release (2025-01-15)

**Features:**
- Basic HNSW/IVF hybrid indexing
- S5 storage integration
- REST API (port 7530)
- Node.js bindings (early version)
- Basic search and insert operations

**Known Limitations:**
- High memory usage (640 MB for 100K vectors)
- Slow load times (~4 seconds for 100K vectors)
- No encryption at rest
- No chunked storage

### Pre-v0.1.0 - Development Phases

**Phase 1-5: Core Infrastructure**
- HNSW index implementation
- IVF index implementation
- Hybrid routing logic
- S5 storage adapter
- Basic REST API

**Phase 6: Testing & Optimization**
- 100K vector testing
- Performance benchmarking
- Memory profiling

**Phase 7: Documentation**
- API documentation
- Integration guides
- Performance tuning guides

**Phase 8: Enhanced S5.js Integration**
- Mock and real S5 modes
- Configuration management
- Seed phrase handling
- Health monitoring

**Phase 9: Node.js Native Bindings**
- napi-rs implementation
- S5 persistence
- Native metadata support
- Production testing

---

## Migration Guide

### Upgrading from v0.1.0 to v0.1.1

**Node.js Bindings:**

```javascript
// v0.1.0 - No chunked storage
const session = await VectorDbSession.create({
  s5Portal: 'http://localhost:5522',
  userSeedPhrase: 'seed',
  sessionId: 'id',
});

// v0.1.1 - Add chunked storage config
const session = await VectorDbSession.create({
  s5Portal: 'http://localhost:5522',
  userSeedPhrase: 'seed',
  sessionId: 'id',
  chunkSize: 10000,        // NEW: Chunked storage
  cacheSizeMb: 150,        // NEW: Cache configuration
  encryptAtRest: true,     // NEW: Encryption (default)
});

// Load with lazy loading
await session.loadUserVectors(cid, { lazyLoad: true }); // NEW: lazyLoad option
```

**REST API:**

- Update base URL: `http://localhost:7530/api/v1` ‚Üí `http://localhost:7533/api/v1`
- S5 timeout increased: 5000ms ‚Üí 30000ms (no code changes needed)

**Data Compatibility:**

- ‚úÖ CIDs from v0.1.0 are **compatible** with v0.1.1
- v0.1.1 saves in chunked format (not backward compatible)
- Recommend re-saving data to benefit from chunked storage

---

**Last Updated:** 2025-01-28 | **API Version:** v0.1.1